{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyHRnetSeg.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "inu6ZLsXIJ_T",
        "Q4FadJmqC5SQ",
        "mqjupOXqCyv0",
        "rzqp1xWmDSdU",
        "fUujZ9bZDLEK"
      ],
      "mount_file_id": "1xrA0eSU5H8EixEdD5m_WnNHkOoCqeFF1",
      "authorship_tag": "ABX9TyM+i+S3wEYMSjJ6RNoFJOnP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoiTK/deep_learning_with_pytorch/blob/main/MyHRnetSeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inu6ZLsXIJ_T"
      },
      "source": [
        "#install dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxPdzzwTCUax"
      },
      "source": [
        "!git clone https://github.com/HRNet/HRNet-Semantic-Segmentation "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QceQCM7iG8cQ"
      },
      "source": [
        "!pip install -r /content/HRNet-Semantic-Segmentation/requirements.txt\n",
        "!pip install imgaug==0.2.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Bd_IRiED7m"
      },
      "source": [
        "!cp /content/drive/MyDrive/cityscapes/gtFine_trainvaltest.zip /content/HRNet-Semantic-Segmentation/data/cityscapes\n",
        "!unzip /content/HRNet-Semantic-Segmentation/data/cityscapes/gtFine_trainvaltest.zip /content/HRNet-Semantic-Segmentation/data/cityscapes\n",
        "%cd HRNet-Semantic-Segmentation"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8L6pMLsQhbM",
        "outputId": "5f2aa6fe-17e6-404a-9102-41ae0b67657e"
      },
      "source": [
        "!mkdir output\n",
        "!mkdir log"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘output’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4FadJmqC5SQ"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zzzG79wbKWe"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import functools\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch._utils\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqjupOXqCyv0"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhN5tiJ3bmHT"
      },
      "source": [
        "BatchNorm2d = nn.BatchNorm2d\n",
        "BN_MOMENTUM = 0.01\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "    self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
        "    self.relu = nn.ReLU(inplace=False)\n",
        "    self.conv2 = conv3x3(planes, planes)\n",
        "    self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "  \n",
        "  def forward(self, x):\n",
        "    residual = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "        residual = self.downsample(x)\n",
        "\n",
        "    out = out + residual\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxf7tlzcfQpB"
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "    super(Bottleneck, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "    self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
        "    self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "    self.bn3 = BatchNorm2d(planes * self.expansion, momentum=BN_MOMENTUM)\n",
        "    self.relu = nn.ReLU(inplace=False)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "  \n",
        "  def forward(self, x):\n",
        "    residual = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv3(out)\n",
        "    out = self.bn3(out)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "        residual = self.downsample(x)\n",
        "\n",
        "    out = out + residual\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5J9U4_if32h"
      },
      "source": [
        "class HighResolutionModule(nn.Module):\n",
        "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
        "                 num_channels, fuse_method, multi_scale_output=True):\n",
        "      super(HighResolutionModule, self).__init__()\n",
        "      self._check_branches(num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
        "\n",
        "      self.num_inchannels = num_inchannels\n",
        "      self.fuse_method = fuse_method\n",
        "      self.num_branches = num_branches\n",
        "\n",
        "      self.multi_scale_output = multi_scale_output\n",
        "\n",
        "      self.branches = self._make_branches(num_branches, blocks, num_blocks, num_channels)\n",
        "      self.fuse_layers = self._make_fuse_layers()\n",
        "      self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    def _check_branches(self, num_branches, blocks, num_blocks, num_inchannels, num_channels):\n",
        "      if num_branches != len(num_blocks):\n",
        "          error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(num_branches, len(num_blocks))\n",
        "          logger.error(error_msg)\n",
        "          raise ValueError(error_msg)\n",
        "\n",
        "      if num_branches != len(num_channels):\n",
        "          error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(num_branches, len(num_channels))\n",
        "          logger.error(error_msg)\n",
        "          raise ValueError(error_msg)\n",
        "\n",
        "      if num_branches != len(num_inchannels):\n",
        "          error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(num_branches, len(num_inchannels))\n",
        "          logger.error(error_msg)\n",
        "          raise ValueError(error_msg)\n",
        "\n",
        "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels, stride=1):\n",
        "      downsample = None\n",
        "      if stride != 1 or \\\n",
        "          self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
        "          downsample = nn.Sequential(\n",
        "              nn.Conv2d(self.num_inchannels[branch_index],\n",
        "                        num_channels[branch_index] * block.expansion,\n",
        "                        kernel_size=1, stride=stride, bias=False),\n",
        "              BatchNorm2d(num_channels[branch_index] * block.expansion,\n",
        "                          momentum=BN_MOMENTUM),\n",
        "          )\n",
        "\n",
        "      layers = []\n",
        "      layers.append(block(self.num_inchannels[branch_index],\n",
        "                          num_channels[branch_index], stride, downsample))\n",
        "      self.num_inchannels[branch_index] = \\\n",
        "          num_channels[branch_index] * block.expansion\n",
        "      for i in range(1, num_blocks[branch_index]):\n",
        "          layers.append(block(self.num_inchannels[branch_index],\n",
        "                              num_channels[branch_index]))\n",
        "\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
        "      branches = []\n",
        "\n",
        "      for i in range(num_branches):\n",
        "          branches.append(\n",
        "              self._make_one_branch(i, block, num_blocks, num_channels))\n",
        "\n",
        "      return nn.ModuleList(branches)\n",
        "\n",
        "    def _make_fuse_layers(self):\n",
        "      if self.num_branches == 1:\n",
        "          return None\n",
        "\n",
        "      num_branches = self.num_branches\n",
        "      num_inchannels = self.num_inchannels\n",
        "      fuse_layers = []\n",
        "      for i in range(num_branches if self.multi_scale_output else 1):\n",
        "          fuse_layer = []\n",
        "          for j in range(num_branches):\n",
        "              if j > i:\n",
        "                  fuse_layer.append(nn.Sequential(\n",
        "                      nn.Conv2d(num_inchannels[j],\n",
        "                                num_inchannels[i],\n",
        "                                1,\n",
        "                                1,\n",
        "                                0,\n",
        "                                bias=False),\n",
        "                      BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))\n",
        "              elif j == i:\n",
        "                  fuse_layer.append(None)\n",
        "              else:\n",
        "                  conv3x3s = []\n",
        "                  for k in range(i-j):\n",
        "                      if k == i - j - 1:\n",
        "                          num_outchannels_conv3x3 = num_inchannels[i]\n",
        "                          conv3x3s.append(nn.Sequential(\n",
        "                              nn.Conv2d(num_inchannels[j],\n",
        "                                        num_outchannels_conv3x3,\n",
        "                                        3, 2, 1, bias=False),\n",
        "                              BatchNorm2d(num_outchannels_conv3x3, \n",
        "                                          momentum=BN_MOMENTUM)))\n",
        "                      else:\n",
        "                          num_outchannels_conv3x3 = num_inchannels[j]\n",
        "                          conv3x3s.append(nn.Sequential(\n",
        "                              nn.Conv2d(num_inchannels[j],\n",
        "                                        num_outchannels_conv3x3,\n",
        "                                        3, 2, 1, bias=False),\n",
        "                              BatchNorm2d(num_outchannels_conv3x3,\n",
        "                                          momentum=BN_MOMENTUM),\n",
        "                              nn.ReLU(inplace=False)))\n",
        "                  fuse_layer.append(nn.Sequential(*conv3x3s))\n",
        "          fuse_layers.append(nn.ModuleList(fuse_layer))\n",
        "\n",
        "      return nn.ModuleList(fuse_layers)\n",
        "\n",
        "    def get_num_inchannels(self):\n",
        "      return self.num_inchannels\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.num_branches == 1:\n",
        "          return [self.branches[0](x[0])]\n",
        "\n",
        "      for i in range(self.num_branches):\n",
        "          x[i] = self.branches[i](x[i])\n",
        "\n",
        "      x_fuse = []\n",
        "      for i in range(len(self.fuse_layers)):\n",
        "          y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
        "          for j in range(1, self.num_branches):\n",
        "              if i == j:\n",
        "                  y = y + x[j]\n",
        "              elif j > i:\n",
        "                  width_output = x[i].shape[-1]\n",
        "                  height_output = x[i].shape[-2]\n",
        "                  y = y + F.interpolate(\n",
        "                      self.fuse_layers[i][j](x[j]),\n",
        "                      size=[height_output, width_output],\n",
        "                      mode='bilinear')\n",
        "              else:\n",
        "                  y = y + self.fuse_layers[i][j](x[j])\n",
        "          x_fuse.append(self.relu(y))\n",
        "\n",
        "      return x_fuse"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7yi19fNgnxZ"
      },
      "source": [
        "blocks_dict = {\n",
        "    'BASIC': BasicBlock,\n",
        "    'BOTTLENECK': Bottleneck\n",
        "}\n",
        "\n",
        "class HighResolutionNet(nn.Module):\n",
        "\n",
        "    def __init__(self, config, **kwargs):\n",
        "        extra = config['MODEL']['EXTRA']\n",
        "        super(HighResolutionNet, self).__init__()\n",
        "\n",
        "        # stem net\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn2 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "        self.stage1_cfg = extra['STAGE1']\n",
        "        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n",
        "        block = blocks_dict[self.stage1_cfg['BLOCK']]\n",
        "        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n",
        "        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n",
        "        stage1_out_channel = block.expansion*num_channels\n",
        "\n",
        "        self.stage2_cfg = extra['STAGE2']\n",
        "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
        "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
        "        num_channels = [\n",
        "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
        "        self.transition1 = self._make_transition_layer(\n",
        "            [stage1_out_channel], num_channels)\n",
        "        self.stage2, pre_stage_channels = self._make_stage(\n",
        "            self.stage2_cfg, num_channels)\n",
        "\n",
        "        self.stage3_cfg = extra['STAGE3']\n",
        "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
        "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
        "        num_channels = [\n",
        "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
        "        self.transition2 = self._make_transition_layer(\n",
        "            pre_stage_channels, num_channels)\n",
        "        self.stage3, pre_stage_channels = self._make_stage(\n",
        "            self.stage3_cfg, num_channels)\n",
        "\n",
        "        self.stage4_cfg = extra['STAGE4']\n",
        "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
        "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
        "        num_channels = [\n",
        "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
        "        self.transition3 = self._make_transition_layer(\n",
        "            pre_stage_channels, num_channels)\n",
        "        self.stage4, pre_stage_channels = self._make_stage(\n",
        "            self.stage4_cfg, num_channels, multi_scale_output=True)\n",
        "        \n",
        "        last_inp_channels = np.int(np.sum(pre_stage_channels))\n",
        "\n",
        "        self.last_layer = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=last_inp_channels,\n",
        "                out_channels=last_inp_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0),\n",
        "            BatchNorm2d(last_inp_channels, momentum=BN_MOMENTUM),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv2d(\n",
        "                in_channels=last_inp_channels,\n",
        "                out_channels=config['DATASET']['NUM_CLASSES'],\n",
        "                kernel_size=extra['FINAL_CONV_KERNEL'],\n",
        "                stride=1,\n",
        "                padding=1 if extra['FINAL_CONV_KERNEL'] == 3 else 0)\n",
        "        )\n",
        "\n",
        "    def _make_transition_layer(\n",
        "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
        "        num_branches_cur = len(num_channels_cur_layer)\n",
        "        num_branches_pre = len(num_channels_pre_layer)\n",
        "\n",
        "        transition_layers = []\n",
        "        for i in range(num_branches_cur):\n",
        "            if i < num_branches_pre:\n",
        "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
        "                    transition_layers.append(nn.Sequential(\n",
        "                        nn.Conv2d(num_channels_pre_layer[i],\n",
        "                                  num_channels_cur_layer[i],\n",
        "                                  3,\n",
        "                                  1,\n",
        "                                  1,\n",
        "                                  bias=False),\n",
        "                        BatchNorm2d(\n",
        "                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n",
        "                        nn.ReLU(inplace=False)))\n",
        "                else:\n",
        "                    transition_layers.append(None)\n",
        "            else:\n",
        "                conv3x3s = []\n",
        "                for j in range(i+1-num_branches_pre):\n",
        "                    inchannels = num_channels_pre_layer[-1]\n",
        "                    outchannels = num_channels_cur_layer[i] \\\n",
        "                        if j == i-num_branches_pre else inchannels\n",
        "                    conv3x3s.append(nn.Sequential(\n",
        "                        nn.Conv2d(\n",
        "                            inchannels, outchannels, 3, 2, 1, bias=False),\n",
        "                        BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n",
        "                        nn.ReLU(inplace=False)))\n",
        "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
        "\n",
        "        return nn.ModuleList(transition_layers)\n",
        "\n",
        "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(inplanes, planes, stride, downsample))\n",
        "        inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_stage(self, layer_config, num_inchannels,\n",
        "                    multi_scale_output=True):\n",
        "        num_modules = layer_config['NUM_MODULES']\n",
        "        num_branches = layer_config['NUM_BRANCHES']\n",
        "        num_blocks = layer_config['NUM_BLOCKS']\n",
        "        num_channels = layer_config['NUM_CHANNELS']\n",
        "        block = blocks_dict[layer_config['BLOCK']]\n",
        "        fuse_method = layer_config['FUSE_METHOD']\n",
        "\n",
        "        modules = []\n",
        "        for i in range(num_modules):\n",
        "            # multi_scale_output is only used last module\n",
        "            if not multi_scale_output and i == num_modules - 1:\n",
        "                reset_multi_scale_output = False\n",
        "            else:\n",
        "                reset_multi_scale_output = True\n",
        "            modules.append(\n",
        "                HighResolutionModule(num_branches,\n",
        "                                      block,\n",
        "                                      num_blocks,\n",
        "                                      num_inchannels,\n",
        "                                      num_channels,\n",
        "                                      fuse_method,\n",
        "                                      reset_multi_scale_output)\n",
        "            )\n",
        "            num_inchannels = modules[-1].get_num_inchannels()\n",
        "\n",
        "        return nn.Sequential(*modules), num_inchannels\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        #print(x.shape)\n",
        "        x = self.layer1(x)\n",
        "        #print(x.shape)\n",
        "        x_list = []\n",
        "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
        "            if self.transition1[i] is not None:\n",
        "                x_list.append(self.transition1[i](x))\n",
        "            else:\n",
        "                x_list.append(x)\n",
        "        y_list = self.stage2(x_list)\n",
        "\n",
        "        x_list = []\n",
        "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
        "            if self.transition2[i] is not None:\n",
        "                if i < self.stage2_cfg['NUM_BRANCHES']:\n",
        "                    x_list.append(self.transition2[i](y_list[i]))\n",
        "                else:\n",
        "                    x_list.append(self.transition2[i](y_list[-1]))\n",
        "            else:\n",
        "                x_list.append(y_list[i])\n",
        "        y_list = self.stage3(x_list)\n",
        "\n",
        "        x_list = []\n",
        "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
        "            if self.transition3[i] is not None:\n",
        "                if i < self.stage3_cfg['NUM_BRANCHES']:\n",
        "                    x_list.append(self.transition3[i](y_list[i]))\n",
        "                else:\n",
        "                    x_list.append(self.transition3[i](y_list[-1]))\n",
        "            else:\n",
        "                x_list.append(y_list[i])\n",
        "        x = self.stage4(x_list)\n",
        "        #print(x.shape)\n",
        "        # Upsampling\n",
        "        x0_h, x0_w = x[0].size(2), x[0].size(3)\n",
        "        #x0_h, x0_w = x0_h* 4, x0_w * 2 \n",
        "        #print(x0_h, x0_w)\n",
        "        x1 = F.upsample(x[1], size=(x0_h, x0_w), mode='bilinear')\n",
        "        x2 = F.upsample(x[2], size=(x0_h, x0_w), mode='bilinear')\n",
        "        x3 = F.upsample(x[3], size=(x0_h, x0_w), mode='bilinear')\n",
        "\n",
        "        x = torch.cat([x[0], x1, x2, x3], 1)\n",
        "\n",
        "        x = self.last_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def init_weights(self, pretrained='',):\n",
        "        logger.info('=> init weights from normal distribution')\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, std=0.001)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        if pretrained:\n",
        "            pretrained_dict = torch.load(pretrained)\n",
        "            logger.info('=> loading pretrained model {}'.format(pretrained))\n",
        "            model_dict = self.state_dict()\n",
        "            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
        "                               if k in model_dict.keys()}\n",
        "            for k, _ in pretrained_dict.items():\n",
        "                logger.info(\n",
        "                    '=> loading {} pretrained model {}'.format(k, pretrained))\n",
        "            model_dict.update(pretrained_dict)\n",
        "            self.load_state_dict(model_dict)\n",
        "\n",
        "def get_seg_model(cfg, **kwargs):\n",
        "    model = HighResolutionNet(cfg, **kwargs)\n",
        "    model.init_weights(cfg['MODEL']['PRETRAINED'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1gFDhm7C-aG"
      },
      "source": [
        "#Create config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9asjZpqhImJ"
      },
      "source": [
        "config = {}\n",
        "\n",
        "config['OUTPUT'] = {\n",
        "    'DIR': './output'\n",
        "}\n",
        "config['WORKERS'] = 4\n",
        "\n",
        "config['DATASET'] = {\n",
        "  'DATASET': 'cityscapes',\n",
        "  'ROOT': 'data/',\n",
        "  'TEST_SET': 'list/cityscapes/val.lst',\n",
        "  'TRAIN_SET': 'list/cityscapes/train.lst',\n",
        "  'NUM_CLASSES': 19,\n",
        "}\n",
        "\n",
        "#config['PRETRAINED'] = None 'PRETRAINED': None,\n",
        "\n",
        "config['MODEL'] = {\n",
        "    'PRETRAINED': None,\n",
        "    'EXTRA':\n",
        "      {'FINAL_CONV_KERNEL': 1,\n",
        "      'STAGE1': {'BLOCK': 'BOTTLENECK', \n",
        "                  'FUSE_METHOD': 'SUM',\n",
        "                  'NUM_BLOCKS': [1],\n",
        "                  'NUM_CHANNELS': [32],\n",
        "                  'NUM_MODULES': 1,\n",
        "                  'NUM_RANCHES': 1\n",
        "                },\n",
        "      'STAGE2': {'BLOCK': 'BASIC',\n",
        "                  'FUSE_METHOD': 'SUM',\n",
        "                  'NUM_BLOCKS': [2, 2],\n",
        "                  'NUM_BRANCHES': 2,\n",
        "                  'NUM_CHANNELS': [16, 32],\n",
        "                  'NUM_MODULES': 1\n",
        "                },\n",
        "      'STAGE3':{'BLOCK': 'BASIC',\n",
        "                'FUSE_METHOD': 'SUM',\n",
        "                'NUM_BLOCKS': [2, 2, 2],\n",
        "                'NUM_BRANCHES': 3,\n",
        "                'NUM_CHANNELS': [16, 32, 64],\n",
        "                'NUM_MODULES': 1\n",
        "                },\n",
        "      'STAGE4': {'BLOCK': 'BASIC',\n",
        "                'FUSE_METHOD': 'SUM',\n",
        "                'NUM_BLOCKS': [2, 2, 2, 2],\n",
        "                'NUM_BRANCHES': 4,\n",
        "                'NUM_CHANNELS': [16, 32, 64, 128],\n",
        "                'NUM_MODULES': 1\n",
        "                }\n",
        "      }\n",
        "}\n",
        "config['LOSS'] = {\n",
        "  'USE_OHEM': False,\n",
        "  'OHEMTHRES': 0.9,\n",
        "  'OHEMKEEP': 131072,\n",
        "}\n",
        "\n",
        "config['TRAIN']={\n",
        "  'IMAGE_SIZE':[1024, 512],\n",
        "  'BASE_SIZE': 2048,\n",
        "  'BATCH_SIZE_PER_GPU': 3,\n",
        "  'SHUFFLE': True,\n",
        "  'BEGIN_EPOCH': 0,\n",
        "  'END_EPOCH': 30, #484\n",
        "  'RESUME': True,\n",
        "  'OPTIMIZER': 'sgd',\n",
        "  'LR': 0.01,\n",
        "  'WD': 0.0005,\n",
        "  'MOMENTUM': 0.9,\n",
        "  'NESTEROV': False,\n",
        "  'FLIP': True,\n",
        "  'MULTI_SCALE': True,\n",
        "  'DOWNSAMPLERATE': 1,\n",
        "  'IGNORE_LABEL': 255,\n",
        "  'SCALE_FACTOR': 16,\n",
        "}\n",
        "config['TEST'] = {\n",
        "  'IMAGE_SIZE':[2048, 1024],\n",
        "  'BASE_SIZE': 2048,\n",
        "  'BATCH_SIZE_PER_GPU': 4,\n",
        "  'FLIP_TEST': False,\n",
        "  'MULTI_SCALE': False,\n",
        "  'NUM_SAMPLES': 0,\n",
        "}"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1A7ygd7hWy7"
      },
      "source": [
        "# model = get_seg_model(config)\n",
        "# dump_input = torch.rand((1, 3, 256, 1600))\n",
        "# output = model(dump_input)\n",
        "# print(output.shape)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzqp1xWmDSdU"
      },
      "source": [
        "#Second Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40-zLGYriX2S"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import pprint\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import logging\n",
        "import time\n",
        "import timeit\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "#import _init_paths\n",
        "#import models\n",
        "import datasets\n",
        "from config import config\n",
        "from config import update_config\n",
        "from core.criterion import CrossEntropy, OhemCrossEntropy\n",
        "from core.function import train, validate\n",
        "from utils.modelsummary import get_model_summary\n",
        "from utils.utils import create_logger, FullModel"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUt-2kpTjP7f"
      },
      "source": [
        "def rectangle(img, img_ano, centers, max_side):\n",
        "    \"\"\"\n",
        "    img     …四角形の線のみの2次元画像\n",
        "    img_ano …あのーテーション画像\n",
        "    centers …center座標のlist\n",
        "    max_side…辺の最大長さの1/2 \n",
        "    \"\"\"\n",
        "    if max_side < 3: #max_sideが小さすぎるとき\n",
        "        max_side = 4\n",
        "    #辺の長さの1/2を定義\n",
        "    side_x = np.random.randint(3, int(max_side))\n",
        "    side_y = np.random.randint(3, int(max_side))    \n",
        "\n",
        "    #中心の座標,(x, y)を定義\n",
        "    x = np.random.randint(max_side + 1, img.shape[0] - (max_side + 1))\n",
        "    y = np.random.randint(max_side + 1, img.shape[1] - (max_side + 1))\n",
        "\n",
        "    #過去の中心位置と近い位置が含まれた場合,inputデータをそのまま返す\n",
        "    for center in centers:\n",
        "        if np.abs(center[0] - x) < (2 *max_side + 1):\n",
        "            if np.abs(center[1] - y) < (2 * max_side + 1):\n",
        "                return img, img_ano, centers\n",
        "\n",
        "    img[x - side_x : x + side_x, y - side_y] = 1.0      #上辺\n",
        "    img[x - side_x : x + side_x, y + side_y] = 1.0      #下辺\n",
        "    img[x - side_x, y - side_y : y + side_y] = 1.0      #左辺\n",
        "    img[x + side_x, y - side_y : y + side_y + 1] = 1.0  #右辺\n",
        "    img_ano[x - side_x : x + side_x + 1, y - side_y : y + side_y + 1] = 1.0\n",
        "    centers.append([x, y])\n",
        "    return img, img_ano, centers"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHNOZZHDE5Q"
      },
      "source": [
        "#Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "vDRb0aXAJEZE",
        "outputId": "2b6a7ae2-f280-455b-8f9c-c3fc5274cb63"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# build model\n",
        "print(config)\n",
        "model = get_seg_model(config).to(device)\n",
        "dump_input = torch.rand((1, 3, config['TRAIN']['IMAGE_SIZE'][1], config['TRAIN']['IMAGE_SIZE'][0]))\n",
        "final_output_dir = config['OUTPUT']['DIR']\n",
        "\n",
        "\n",
        "# copy model file\n",
        "this_dir = '/HRNet-Semantic-Segmentation'\n",
        "models_dst_dir = os.path.join(final_output_dir, 'models')\n",
        "if os.path.exists(models_dst_dir):\n",
        "    shutil.rmtree(models_dst_dir)\n",
        "shutil.copytree('./lib/models', models_dst_dir)\n",
        "gpus = 1\n",
        "\n",
        "# prepare data\n",
        "crop_size = (config['TRAIN']['IMAGE_SIZE'][1], config['TRAIN']['IMAGE_SIZE'][0])\n",
        "train_dataset = eval('datasets.'+config['DATASET']['DATASET'])(\n",
        "                    root=config['DATASET']['ROOT'],\n",
        "                    list_path=config['DATASET']['TRAIN_SET'],\n",
        "                    num_samples=None,\n",
        "                    num_classes=config['DATASET']['NUM_CLASSES'],\n",
        "                    multi_scale=config['TRAIN']['MULTI_SCALE'],\n",
        "                    flip=config['TRAIN']['FLIP'],\n",
        "                    ignore_label=config['TRAIN']['IGNORE_LABEL'],\n",
        "                    base_size=config['TRAIN']['BASE_SIZE'],\n",
        "                    crop_size=crop_size,\n",
        "                    downsample_rate=config['TRAIN']['DOWNSAMPLERATE'],\n",
        "                    scale_factor=config['TRAIN']['SCALE_FACTOR'])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "                  train_dataset,\n",
        "                  batch_size=config['TRAIN']['BATCH_SIZE_PER_GPU']*gpus,\n",
        "                  shuffle=config['TRAIN']['SHUFFLE'],\n",
        "                  num_workers=config['WORKERS'],\n",
        "                  pin_memory=True,\n",
        "                  drop_last=True)\n",
        "\n",
        "\n",
        "test_size = (config['TEST']['IMAGE_SIZE'][1], config['TEST']['IMAGE_SIZE'][0])\n",
        "test_dataset = eval('datasets.'+config['DATASET']['DATASET'])(\n",
        "                    root=config['DATASET']['ROOT'],\n",
        "                    list_path=config['DATASET']['TEST_SET'],\n",
        "                    num_samples=config['TEST']['NUM_SAMPLES'],\n",
        "                    num_classes=config['DATASET']['NUM_CLASSES'],\n",
        "                    multi_scale=False,\n",
        "                    flip=False,\n",
        "                    ignore_label=config['TRAIN']['IGNORE_LABEL'],\n",
        "                    base_size=config['TEST']['BASE_SIZE'],\n",
        "                    crop_size=test_size,\n",
        "                    downsample_rate=1)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config['TEST']['BATCH_SIZE_PER_GPU']*gpus,\n",
        "        shuffle=False,\n",
        "        num_workers=config['WORKERS'],\n",
        "        pin_memory=True)\n",
        "\n",
        "\n",
        "# criterion\n",
        "if config['LOSS']['USE_OHEM']:\n",
        "    criterion = OhemCrossEntropy(ignore_label=config['TRAIN']['IGNORE_LABEL'],\n",
        "                                  thres=config['LOSS']['OHEMTHRES'],\n",
        "                                  min_kept=config['LOSS']['OHEMKEEP'],\n",
        "                                  weight=train_dataset.class_weights)\n",
        "else:\n",
        "    criterion = CrossEntropy(ignore_label=config['TRAIN']['IGNORE_LABEL'],\n",
        "                              weight=train_dataset.class_weights)\n",
        "\n",
        "model = FullModel(model, criterion).to(device)\n",
        "#model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
        "\n",
        "# optimizer\n",
        "if config['TRAIN']['OPTIMIZER'] == 'sgd':\n",
        "    optimizer = torch.optim.SGD([{'params':\n",
        "                              filter(lambda p: p.requires_grad,\n",
        "                                      model.parameters()),\n",
        "                              'lr': config['TRAIN']['LR']}],\n",
        "                            lr=config['TRAIN']['LR'],\n",
        "                            momentum=config['TRAIN']['MOMENTUM'],\n",
        "                            weight_decay=config['TRAIN']['WD'],\n",
        "                            nesterov=config['TRAIN']['NESTEROV'],\n",
        "                            )\n",
        "else:\n",
        "    raise ValueError('Only Support SGD optimizer')\n",
        "\n",
        "\n",
        "epoch_iters = np.int(train_dataset.__len__() / \n",
        "                        config['TRAIN']['BATCH_SIZE_PER_GPU'] / gpus)\n",
        "best_mIoU = 0\n",
        "last_epoch = 0\n",
        "if config['TRAIN']['RESUME']:\n",
        "    model_state_file = os.path.join(final_output_dir, 'checkpoint.pth.tar')\n",
        "    if os.path.isfile(model_state_file):#消してもいい\n",
        "        checkpoint = torch.load(model_state_file)\n",
        "        best_mIoU = checkpoint['best_mIoU']\n",
        "        last_epoch = checkpoint['epoch']\n",
        "        model.module.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        #logger.info(\"=> loaded checkpoint (epoch {})\".format(checkpoint['epoch']))\n",
        "\n",
        "tb_log_dir = 'log/'\n",
        "writer_dict = {\n",
        "        'writer': SummaryWriter(tb_log_dir),\n",
        "        'train_global_steps': 0,\n",
        "        'valid_global_steps': 0,\n",
        "}\n",
        "start = timeit.default_timer()\n",
        "end_epoch = config['TRAIN']['END_EPOCH']\n",
        "num_iters = config['TRAIN']['END_EPOCH'] * epoch_iters\n",
        "extra_iters = 0 * epoch_iters\n",
        "\n",
        "for epoch in range(last_epoch, end_epoch):\n",
        "    if epoch < config['TRAIN']['END_EPOCH']:\n",
        "        train(config, epoch, config['TRAIN']['END_EPOCH'], \n",
        "              epoch_iters, config['TRAIN']['LR'], num_iters,\n",
        "              trainloader, optimizer, model, writer_dict)\n",
        "\n",
        "    #logger.info('=> saving checkpoint to {}'.format(final_output_dir + 'checkpoint.pth.tar'))\n",
        "    torch.save({\n",
        "        'epoch': epoch+1,\n",
        "        'best_mIoU': best_mIoU,\n",
        "        'state_dict': model.module.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    }, os.path.join(final_output_dir,'checkpoint.pth.tar'))\n",
        "    valid_loss, mean_IoU, IoU_array = validate(\n",
        "                    config, testloader, model, writer_dict)\n",
        "    if mean_IoU > best_mIoU:\n",
        "        best_mIoU = mean_IoU\n",
        "        torch.save(model.module.state_dict(),\n",
        "                    os.path.join(final_output_dir, 'best.pth'))\n",
        "    msg = 'Loss: {:.3f}, MeanIU: {: 4.4f}, Best_mIoU: {: 4.4f}'.format(\n",
        "                valid_loss, mean_IoU, best_mIoU)\n",
        "    print(msg)\n",
        "    print(IoU_array)\n",
        "    #logging.info(msg)\n",
        "    #logging.info(IoU_array)\n",
        "\n",
        "torch.save(model.module.state_dict(), os.path.join(final_output_dir, 'final_state.pth'))\n",
        "\n",
        "writer_dict['writer'].close()\n",
        "end = timeit.default_timer()\n",
        "print('Hours: %d' % np.int((end-start)/3600))\n",
        "print('Done')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "{'OUTPUT': {'DIR': './output'}, 'WORKERS': 4, 'DATASET': {'DATASET': 'cityscapes', 'ROOT': 'data/', 'TEST_SET': 'list/cityscapes/val.lst', 'TRAIN_SET': 'list/cityscapes/train.lst', 'NUM_CLASSES': 19}, 'MODEL': {'PRETRAINED': None, 'EXTRA': {'FINAL_CONV_KERNEL': 1, 'STAGE1': {'BLOCK': 'BOTTLENECK', 'FUSE_METHOD': 'SUM', 'NUM_BLOCKS': [1], 'NUM_CHANNELS': [32], 'NUM_MODULES': 1, 'NUM_RANCHES': 1}, 'STAGE2': {'BLOCK': 'BASIC', 'FUSE_METHOD': 'SUM', 'NUM_BLOCKS': [2, 2], 'NUM_BRANCHES': 2, 'NUM_CHANNELS': [16, 32], 'NUM_MODULES': 1}, 'STAGE3': {'BLOCK': 'BASIC', 'FUSE_METHOD': 'SUM', 'NUM_BLOCKS': [2, 2, 2], 'NUM_BRANCHES': 3, 'NUM_CHANNELS': [16, 32, 64], 'NUM_MODULES': 1}, 'STAGE4': {'BLOCK': 'BASIC', 'FUSE_METHOD': 'SUM', 'NUM_BLOCKS': [2, 2, 2, 2], 'NUM_BRANCHES': 4, 'NUM_CHANNELS': [16, 32, 64, 128], 'NUM_MODULES': 1}}}, 'LOSS': {'USE_OHEM': False, 'OHEMTHRES': 0.9, 'OHEMKEEP': 131072}, 'TRAIN': {'IMAGE_SIZE': [1024, 512], 'BASE_SIZE': 2048, 'BATCH_SIZE_PER_GPU': 3, 'SHUFFLE': True, 'BEGIN_EPOCH': 0, 'END_EPOCH': 30, 'RESUME': True, 'OPTIMIZER': 'sgd', 'LR': 0.01, 'WD': 0.0005, 'MOMENTUM': 0.9, 'NESTEROV': False, 'FLIP': True, 'MULTI_SCALE': True, 'DOWNSAMPLERATE': 1, 'IGNORE_LABEL': 255, 'SCALE_FACTOR': 16}, 'TEST': {'IMAGE_SIZE': [2048, 1024], 'BASE_SIZE': 2048, 'BATCH_SIZE_PER_GPU': 4, 'FLIP_TEST': False, 'MULTI_SCALE': False, 'NUM_SAMPLES': 0}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-8afa1ffa03e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m         train(config, epoch, config['TRAIN']['END_EPOCH'], \n\u001b[1;32m    119\u001b[0m               \u001b[0mepoch_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TRAIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m               trainloader, optimizer, model, writer_dict)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m#logger.info('=> saving checkpoint to {}'.format(final_output_dir + 'checkpoint.pth.tar'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HRNet-Semantic-Segmentation/tools/../lib/core/function.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, epoch, num_epoch, epoch_iters, base_lr, num_iters, trainloader, optimizer, model, writer_dict)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwriter_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'writer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mglobal_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwriter_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_global_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/HRNet-Semantic-Segmentation/tools/../lib/datasets/cityscapes.py\", line 105, in __getitem__\n    size = image.shape\nAttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJE0TPP3jU6J"
      },
      "source": [
        "# num_images = 1000                                   #生成する画像数\n",
        "# length = 64                                          #画像のサイズ\n",
        "# imgs = np.zeros([num_images, 3, length, length])     #ゼロ行列を生成,入力画像\n",
        "# imgs_ano = np.zeros([num_images, 4, length, length]) #出力画像\n",
        "\n",
        "# for i in range(num_images):\n",
        "#     centers = []\n",
        "#     img = np.zeros([length, length])\n",
        "#     img_ano = np.zeros([64, 64])\n",
        "#     for j in range(6):                       #四角形を最大6つ生成\n",
        "#         img, img_ano, centers = rectangle(img, img_ano, centers, 12) \n",
        "#     imgs[i, 0, :, :] = img\n",
        "#     imgs_ano[i, 0, :, :] = img_ano\n",
        "\n",
        "# imgs = torch.tensor(imgs, dtype = torch.float32)                 #ndarray - torch.tensor\n",
        "# imgs_ano = torch.tensor(imgs_ano, dtype = torch.float32)           #ndarray - torch.tensor\n",
        "# data_set = TensorDataset(imgs, imgs_ano)\n",
        "# data_loader = DataLoader(data_set, batch_size = 100, shuffle = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "YrMdFZgAjYAP",
        "outputId": "a5f8784d-758e-486d-babb-a7d24c9864a7"
      },
      "source": [
        "#before\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)\n",
        "# net = get_seg_model(config).to(device)                \n",
        "# loss_fn = nn.MSELoss()                                #損失関数の定義\n",
        "# optimizer = optim.Adam(net.parameters(), lr = 0.01)\n",
        "\n",
        "# losses = []                                     #epoch毎のlossを記録\n",
        "# epoch_time = 30\n",
        "\n",
        "# for epoch in range(epoch_time):\n",
        "#     running_loss = 0.0                          #epoch毎のlossの計算\n",
        "#     net.train()\n",
        "#     for i, (XX, yy) in enumerate(data_loader):\n",
        "#         optimizer.zero_grad()  \n",
        "#         XX = XX.to(device) \n",
        "#         yy = yy.to(device)    \n",
        "#         y_pred = net(XX)\n",
        "#         loss = loss_fn(y_pred, yy)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         running_loss += loss.item()\n",
        "#     print(\"epoch:\",epoch, \" loss:\", running_loss/(i + 1))\n",
        "#     losses.append(running_loss/(i + 1))\n",
        "\n",
        "# #lossの可視化\n",
        "# plt.plot(losses)\n",
        "# plt.ylabel(\"loss\")\n",
        "# plt.xlabel(\"epoch time\")\n",
        "# plt.savefig(\"loss_auto\")\n",
        "# plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0  loss: 0.2911895910277963\n",
            "epoch: 1  loss: 0.07214939072728158\n",
            "epoch: 2  loss: 0.022255991492420434\n",
            "epoch: 3  loss: 0.010634985845535993\n",
            "epoch: 4  loss: 0.006224869564175606\n",
            "epoch: 5  loss: 0.004203650914132595\n",
            "epoch: 6  loss: 0.0028989467537030578\n",
            "epoch: 7  loss: 0.0019225770607590674\n",
            "epoch: 8  loss: 0.0013178622233681382\n",
            "epoch: 9  loss: 0.001000720646698028\n",
            "epoch: 10  loss: 0.0007092638756148517\n",
            "epoch: 11  loss: 0.0006199306604685262\n",
            "epoch: 12  loss: 0.0005527435569092631\n",
            "epoch: 13  loss: 0.00034281817497685554\n",
            "epoch: 14  loss: 0.0003072687642998062\n",
            "epoch: 15  loss: 0.0002366795335547067\n",
            "epoch: 16  loss: 0.0002666868225787766\n",
            "epoch: 17  loss: 0.000219063188706059\n",
            "epoch: 18  loss: 0.00019897070378647186\n",
            "epoch: 19  loss: 0.00016078223488875666\n",
            "epoch: 20  loss: 0.00020950123871443793\n",
            "epoch: 21  loss: 0.00015110055246623234\n",
            "epoch: 22  loss: 0.00010922202563961037\n",
            "epoch: 23  loss: 0.00013579942387877963\n",
            "epoch: 24  loss: 0.00010047529249277432\n",
            "epoch: 25  loss: 9.305216990469489e-05\n",
            "epoch: 26  loss: 7.601583820360247e-05\n",
            "epoch: 27  loss: 0.00013887263885408173\n",
            "epoch: 28  loss: 0.00012457682387321257\n",
            "epoch: 29  loss: 0.00013250241536297836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfAUlEQVR4nO3dfXBdd33n8fdHV1fWle3o2oliwHZiBxyIeKizVcJQIE1pnCalG9PZAEkLG9qUQIe0dNjZARYGWNOdSaHbLh2yJV7ILGGhJgTY9Za0JgSShSkBKyFA42DiOA+2CbGIbdmOH/Rwv/vHOZKurnXlK1vHV7rn85rR6J5HfY+udT/+nd85v6OIwMzMbCptzS7AzMzmLoeEmZnV5ZAwM7O6HBJmZlaXQ8LMzOpqb3YBs+Wcc86JVatWNbsMM7N55cEHH/xVRPTUW55pSEi6CvgUUAA+GxG31Cx/N/AeYBQ4DNwUEdvSZR8EbkyX/XlEbJnuZ61atYr+/v7ZPwgzsxYm6anplmd2uklSAbgVuBroBa6X1Fuz2pci4pURsRb4BPA36ba9wHXAy4GrgP+e7s/MzM6gLPskLgV2RMTOiBgCNgHrq1eIiINVkwuBsTv71gObIuJ4RDwB7Ej3Z2ZmZ1CWp5uWA7uqpncDr65dSdJ7gPcBHcAbqrZ9oGbb5VNsexNwE8B55503K0WbmdmEpl/dFBG3RsSLgfcDH57hthsjoi8i+np66va7mJnZKcoyJPYAK6umV6Tz6tkEvOkUtzUzswxkGRJbgTWSVkvqIOmI3ly9gqQ1VZNvBB5LX28GrpO0QNJqYA3wwwxrNTOzKWTWJxERI5JuBraQXAJ7e0Q8ImkD0B8Rm4GbJV0BDAP7gRvSbR+RdCewDRgB3hMRo1nVamZmU1OrDBXe19cXp3KfxKFjw3z2u0/wWy87l7UryxlUZmY2d0l6MCL66i1vesd1s1Uq8Kl7H+PBp/Y3uxQzszkn9yGxuLMdCQaPDDW7FDOzOSf3IdHWJrpLRQ4cHW52KWZmc07uQwKgXCpy4IhDwsyslkMC6O7qcEvCzGwKDgmSloT7JMzMTuSQAMpd7pMwM5uKQwL3SZiZ1eOQIOmTOHhsmNFKa9xYaGY2WxwSJC2JiOTuazMzm+CQIOmTAHzKycyshkOCqpBw57WZ2SQOCaC71AHAAV8Ga2Y2iUMCn24yM6vHIQEs6XJLwsxsKg4J4KzO5NlL7pMwM5vMIQG0F9pY3Nnu001mZjUcEqlyV5FBtyTMzCZxSKTKpQ73SZiZ1XBIpDzIn5nZiRwSqe5SkUH3SZiZTeKQSLklYWZ2IodEaqxPouKRYM3MxjkkUuWuIpWAw0MjzS7FzGzOcEikukvJ0BzulzAzm5BpSEi6StJ2STskfWCK5e+TtE3STyTdK+n8qmWjkh5OvzZnWSdAeXxoDoeEmdmY9qx2LKkA3AqsA3YDWyVtjohtVav9COiLiCOS/hT4BPDWdNnRiFibVX21JoYL970SZmZjsmxJXArsiIidETEEbALWV68QEd+JiCPp5APAigzrmVa55JFgzcxqZRkSy4FdVdO703n13Aj8U9V0p6R+SQ9IetNUG0i6KV2nf2Bg4LSK7R4fLtwtCTOzMZmdbpoJSW8D+oDfrJp9fkTskXQB8G1JP42Ix6u3i4iNwEaAvr6+07p2tVxyn4SZWa0sWxJ7gJVV0yvSeZNIugL4EHBNRBwfmx8Re9LvO4H7gIszrJWO9jYWdhR8Q52ZWZUsQ2IrsEbSakkdwHXApKuUJF0M3EYSEHur5i+RtCB9fQ7wWqC6wzsT5a4OtyTMzKpkdropIkYk3QxsAQrA7RHxiKQNQH9EbAY+CSwCviIJ4OmIuAa4CLhNUoUkyG6puSoqE92lIoO+usnMbFymfRIRcTdwd828j1S9vqLOdv8CvDLL2qZS7iq6JWFmVsV3XFfxIH9mZpM5JKp0l9wnYWZWzSFRJXmE6RARHgnWzAwcEpOUS0WGR4MjQ6PNLsXMbE5wSFSZGL/Jp5zMzMAhMUn3+F3XvgzWzAwcEpOMtST8TAkzs4RDoopPN5mZTeaQqOJB/szMJnNIVBlrSex3n4SZGeCQmKSzWGBBexuDPt1kZgY4JE6QjN/kloSZGTgkTrDEw4WbmY1zSNToLnmQPzOzMQ6JGuWuou+TMDNLOSRqlEsdHPCDh8zMAIfECfzgITOzCQ6JGt1dRY6PVDg27JFgzcwcEjV817WZ2QSHRI2J8ZvcL2Fm5pCoUS6lIeGWhJmZQ6JWd5dDwsxsjEOiRrkr6ZMY9OkmMzOHRC2fbjIzm+CQqNHVUaBYEPsdEmZm2YaEpKskbZe0Q9IHplj+PknbJP1E0r2Szq9adoOkx9KvG7Kss6YmuksdPt1kZkaGISGpANwKXA30AtdL6q1Z7UdAX0S8CrgL+ES67VLgo8CrgUuBj0paklWttXzXtZlZIsuWxKXAjojYGRFDwCZgffUKEfGdiDiSTj4ArEhf/w5wT0Tsi4j9wD3AVRnWOkm55JAwM4NsQ2I5sKtqenc6r54bgX+aybaSbpLUL6l/YGDgNMudUO7q8HDhZmbMkY5rSW8D+oBPzmS7iNgYEX0R0dfT0zNr9STDhbtPwswsy5DYA6ysml6RzptE0hXAh4BrIuL4TLbNStkPHjIzA7INia3AGkmrJXUA1wGbq1eQdDFwG0lA7K1atAW4UtKStMP6ynTeGVHuKnJkaJTjIx4J1szyrT2rHUfEiKSbST7cC8DtEfGIpA1Af0RsJjm9tAj4iiSApyPimojYJ+njJEEDsCEi9mVVa63u8buuhzl3ceFM/Vgzszkns5AAiIi7gbtr5n2k6vUV02x7O3B7dtXVN3bX9eCRYc5d3NmMEszM5oQ50XE910wMF+5+CTPLN4fEFPzgITOzhENiCuMtCV8Ga2Y555CYwtgzJQZ9usnMcs4hMYXFC9optMmnm8ws9xwSU0hGgi36OddmlnsOiTrKpaKfKWFmueeQqKO7q8igQ8LMcs4hUUfZp5vMzBwS9ZS7OtxxbWa555Coo+zTTWZmDol6yqUODh0fYXi00uxSzMyaxiFRx9hd1wd9Q52Z5ZhDog4P8mdm5pCoq7s0Nn6TQ8LM8sshUUd5/MFDvgzWzPLLIVFH2S0JMzOHRD0Tw4U7JMwsvxwSdSzuLCK549rM8s0hUUehTZzVWWTQDx4ysxxzSEyj3FV0S8LMcs0hMQ0PF25meeeQmEZ3V4dPN5lZrjkkppEMF+6WhJnll0NiGuWuoi+BNbNcaygkJL1X0llKfE7SQ5KubGC7qyRtl7RD0gemWH5Zuq8RSdfWLBuV9HD6tbnxQ5o95VKRg8eGGa1EM368mVnTNdqS+OOIOAhcCSwB3g7cMt0GkgrArcDVQC9wvaTemtWeBt4BfGmKXRyNiLXp1zUN1jmryl0dRMChY25NmFk+NRoSSr//LvCFiHikal49lwI7ImJnRAwBm4D11StExJMR8RNgTj60wXddm1neNRoSD0r6JklIbJG0mJN/sC8HdlVN707nNapTUr+kByS9aaoVJN2UrtM/MDAwg103xsOFm1netTe43o3AWmBnRByRtBT4o+zKAuD8iNgj6QLg25J+GhGPV68QERuBjQB9fX2z3nHQXUpGgj3gy2DNLKcabUm8BtgeEQckvQ34MDB4km32ACurplek8xoSEXvS7zuB+4CLG912toy1JAbdkjCznGo0JP4eOCLp14D/ADwO3HGSbbYCayStltQBXAc0dJWSpCWSFqSvzwFeC2xrsNZZ4+HCzSzvGg2JkYgIko7nT0fErcDi6TaIiBHgZmAL8ChwZ0Q8ImmDpGsAJF0iaTfwZuA2SY+km18E9Ev6MfAd4JaIOOMh4afTmVneNdoncUjSB0kufX29pDageLKNIuJu4O6aeR+per2V5DRU7Xb/Aryywdoy015oY/GCdg746XRmllONtiTeChwnuV/ilyQf7J/MrKo5pLuryKBbEmaWUw2FRBoMXwS6Jf0ecCwiTtYn0RI8XLiZ5Vmjw3K8BfghSd/BW4Af1A6j0arKpQ72+xJYM8upRvskPgRcEhF7AST1AN8C7sqqsLmiu6vILw4cbXYZZmZN0WifRNtYQKSem8G285qHCzezPGu0JfHPkrYA/5BOv5Waq5ZaVTJc+BCVStDWdrLhqszMWktDIRER/1HSvyO5qQ1gY0R8Pbuy5o5yqYNKwOGhEc7qPOlVv2ZmLaXRlgQR8VXgqxnWMid1jw3NcWTYIWFmuTNtSEg6BEw1cJ6AiIizMqlqDlnSNTbI3zArlza5GDOzM2zakIiIaYfeyIOJ4cJ9GayZ5U8urlA6HR7kz8zyzCFxEt1+8JCZ5ZhD4iTGRoId9F3XZpZDDomTWNBeoKuj4NNNZpZLDokG+K5rM8srh0QDurs63JIws1xySDSgXCoy6EtgzSyHHBINKHcV2e+WhJnlkEOiAckgfw4JM8sfh0QDuksdDB4dImKqEUrMzFqXQ6IB5a4iw6PBkaHRZpdiZnZGOSQaMD40hy+DNbOccUg0YHyQP991bWY545BoQHcpGS580J3XZpYzDokGLFno001mlk+ZhoSkqyRtl7RD0gemWH6ZpIckjUi6tmbZDZIeS79uyLLOkymXJh48ZGaWJ5mFhKQCcCtwNdALXC+pt2a1p4F3AF+q2XYp8FHg1cClwEclLcmq1pPxg4fMLK+ybElcCuyIiJ0RMQRsAtZXrxART0bET4BKzba/A9wTEfsiYj9wD3BVhrVOq7NYYEF7m/skzCx3sgyJ5cCuqund6bxZ21bSTZL6JfUPDAyccqGN8F3XZpZH87rjOiI2RkRfRPT19PRk+rPKpQ6fbjKz3MkyJPYAK6umV6Tzst42E91uSZhZDmUZEluBNZJWS+oArgM2N7jtFuBKSUvSDusr03lNkwwX7pAws3zJLCQiYgS4meTD/VHgzoh4RNIGSdcASLpE0m7gzcBtkh5Jt90HfJwkaLYCG9J5TZMMF+7TTWaWL+1Z7jwi7gburpn3karXW0lOJU217e3A7VnWNxNlP53OzHJoXndcn0ndpSLHRyocG/ZIsGaWHw6JBk0M8ufWhJnlh0OiQeNDc/gyWDPLEYdEg9ySMLM8ckg0qLvkkDCz/HFINGisJTHo001mliMOiQYt6fJw4WaWPw6JBnV1FCgW5AcPmVmuOCQaJInukm+oM7N8cUjMQLmr6D4JM8sVh8QMlEseCdbM8sUhMQN+8JCZ5Y1DYga6Sx0eCdbMcsUhMQNrli3imcFj7DlwtNmlmJmdEQ6JGbjiomUAfGvbs02uxMzszHBIzMBLzl3EBT0LucchYWY54ZCYoXW9y3hg53N+lKmZ5YJDYoau7F3GSCW4b/veZpdiZpY5h8QMrV25hHMWLeCbPuVkZjngkJihQpu44qJzuX/7AMdH/ChTM2ttDolTsK53GYePj/D9x59rdilmZplySJyC177kHLo6Cr7KycxankPiFHQWC1y2podvPfoslUo0uxwzs8w4JE7Rut5lPHvwOD/ZM9jsUszMMuOQOEVveNm5FNrEPdt+2exSzMwyk2lISLpK0nZJOyR9YIrlCyR9OV3+A0mr0vmrJB2V9HD69Zks6zwVSxZ2cMmqJe6XMLOWlllISCoAtwJXA73A9ZJ6a1a7EdgfES8B/hb4q6plj0fE2vTr3VnVeTrW9b6Anz97mCd/9XyzSzEzy0SWLYlLgR0RsTMihoBNwPqaddYDn09f3wX8tiRlWNOsurI3GfDPrQkza1VZhsRyYFfV9O503pTrRMQIMAicnS5bLelHku6X9PqpfoCkmyT1S+ofGBiY3eobsHJpFy97wWKHhJm1rLnacf0McF5EXAy8D/iSpLNqV4qIjRHRFxF9PT09Z7xISFoT/U/t47nDx5vy883MspRlSOwBVlZNr0jnTbmOpHagG3guIo5HxHMAEfEg8DhwYYa1nrJ1vS+gEnDvzzzgn5m1nixDYiuwRtJqSR3AdcDmmnU2Azekr68Fvh0RIakn7fhG0gXAGmBnhrWeslcsP4sXdnf6lJOZtaT2rHYcESOSbga2AAXg9oh4RNIGoD8iNgOfA74gaQewjyRIAC4DNkgaBirAuyNiX1a1ng5JrOtdxp39uzg6NEqpo9DskszMZk1mIQEQEXcDd9fM+0jV62PAm6fY7qvAV7OsbTat613GHd9/iu8+NsCVL39Bs8sxM5s1c7Xjel559eqzWdzZ7lNOZtZyHBKzoKO9jd966bnc+7O9jHrAPzNrIQ6JWbKudxn7nh/iwaf2N7sUM7NZ45CYJZe/tIdiwQP+mVlrcUjMksWdRV7z4nO4Z9uzRPiUk5m1BofELFrXu4wnnzvCjr2Hm12KmdmscEjMonUXJQP+fdNXOZlZi3BIzKIXdHfyayu6HRJm1jIcErNsXe8yfrzrAM8ePNbsUszMTptDYpat603uuPaNdWbWChwSs+zCZYs4/+wuh4SZtQSHxCyTxLqLlvH9x5/j0LHhZpdjZnZaHBIZWNe7jKHRCrfdv9P3TJjZvOaQyEDfqqW88ZUv5NPf2cE77+jnwJGhZpdkZnZKHBIZKLSJT//BxXz03/Zy/88HeOPffY+HnvaYTmY2/zgkMiKJP3rtar7y7t9Agrd85vt89rs+/WRm84tDImNrV5b5xp+9nje87Fz+8huP8s47HmTwiDu0zWx+cEicAd1dRW57+6/zkd/r5f6f7+V3/+67PLzrQLPLMjM7KYfEGSKJP35dcvoJ4M2f+Rc+970nfPrJzOY0h8QZtnZlmW/8+ev4zQvP5eP/uI13fcGnn8xs7lKr/E+2r68v+vv7m11GwyKCz33vCW75p5+xcEE7l13Yw+UX9nDZhT30LF7Q7PLMLCckPRgRffWWt5/JYmyCJP7k9Rdwyaql3PH9p7j/5wP83x//AoBXLu/m8pf2cPlLe1i7cgmFNjW5WjPLK7ck5ohKJdj2zEHu276X+7YP8NDT+6kEdJeKvH7NOVz+0nP5TbcyzGyWnawl4ZCYowaPDPPdHQPct32A+38+wMCh4wCcs2gBK5eWOG9pFyuXdHHe0i5WpNMv7C651WFmM+KQaAFjrYzv7fgVTww8z679R3h63xGeGTzGaGXi/WtvEy8qJ4HxonInZy9awNkLOzh7UQdnL1zA0oUdnLMo+d7R7msWzKzJfRKSrgI+BRSAz0bELTXLFwB3AL8OPAe8NSKeTJd9ELgRGAX+PCK2ZFnrXNbWJl6xvJtXLO+eNH94tMIvB4/x9L4j7NqXBMeu/Ud5et8R7ts+wL7nhxipTP2fgMWd7WmALKC7VKS7VOSsznbOKhU5qzOdLrVzVmdxfN7iznZKHQUWtLchucVilgeZhYSkAnArsA7YDWyVtDkitlWtdiOwPyJeIuk64K+At0rqBa4DXg68CPiWpAsjYjSreuejYqGNlUu7WLm0a8rlEcHBYyM8d/g4+54f4leHh3ju+ePsOzzEc8+nX4ePs/fQMR7be4iDR0c4dGyYOrkySalYoNRRoFQs0Flsq3qdfHW0t1FsE+2FNooFUSy00d6WvG5Pp5N5E+sU2kSxrY32QjovXdZeEO1tok1CAiHalHT+J9+B2nmIsRxT1fTEPhifbm9ro62N8e+FKea1Sek2yU7HInLiZzg0rTVl2ZK4FNgRETsBJG0C1gPVIbEe+Fj6+i7g00r+2tYDmyLiOPCEpB3p/r6fYb0tR9J4K+GCnsa2qVSC54dGOHhshINHhxk8OszBo8McPDbC4WPDHB2ucHR4lGPDoxwdGuXocPJ1LH19+PgIA4eOMzRaYWQ0GBmtMFwJhtPp4dEKI5WYdJqs1YyFUHWoISaF11jgjJ3uHfttjJ39DYLaM8Hj+6r6GUrDK/0R6TJN2mbSPibtbyLwJtarCteq+RFJjUlNUVVn8p+R6lKr6xoL8Opgrv0d1NZae5y1v5dJ01P8M6reT/rTq/Y7+djr/W7qLahdp3o/47+HmPx7SX53ye9surP7p/P/jN4XnsXGf1/3jNFpyTIklgO7qqZ3A6+ut05EjEgaBM5O5z9Qs+3y2h8g6SbgJoDzzjtv1grPs7Y2sbizyOLOIsvLpcx+TqUSDFfGgiR5PVoVJiOVCsNVy0ZGY/yPrpJ+YlXSP75KVP9BBpXKiX+kYx9sY9uPv04Da7QSjEYwUokT5o2m86b6IB+bHv/br/lgqMTE66TmmPSBO/mDa+x7VWtlbGHVz4iafUwVKGPrTZqetGziGCZ/4E+sXf1BLE39gZ/OGZ93wodi7e+/ZhlV6095nJz4wV6VZ+M/v6rqSQdbu6/qY6/3u5k0v2rlE9aJ6pcx/p+B2pA8McxPTIOYqoLqgz+J85cubGzFUzCv75OIiI3ARkg6rptcjs1AW5tY0FZgwbz+F2jW+rK8xGUPsLJqekU6b8p1JLUD3SQd2I1sa2ZmGcsyJLYCayStltRB0hG9uWadzcAN6etrgW9H0r7bDFwnaYGk1cAa4IcZ1mpmZlPIrLGf9jHcDGwhuQT29oh4RNIGoD8iNgOfA76QdkzvIwkS0vXuJOnkHgHe4yubzMzOPN9MZ2aWYye7mc633ZqZWV0OCTMzq8shYWZmdTkkzMysrpbpuJY0ADx1Grs4B/jVLJUzF7Ta8UDrHVOrHQ+03jG12vHAicd0fkTUHbinZULidEnqn66Hf75pteOB1jumVjseaL1jarXjgZkfk083mZlZXQ4JMzOryyExYWOzC5hlrXY80HrH1GrHA613TK12PDDDY3KfhJmZ1eWWhJmZ1eWQMDOzunIfEpKukrRd0g5JH2h2PbNB0pOSfirpYUnzbtRDSbdL2ivpX6vmLZV0j6TH0u9LmlnjTNU5po9J2pO+Tw9L+t1m1jgTklZK+o6kbZIekfTedP68fJ+mOZ75/B51SvqhpB+nx/Sf0/mrJf0g/cz7cvooh/r7yXOfhKQC8HNgHckjUrcC10fEtmk3nOMkPQn0RcS8vAlI0mXAYeCOiHhFOu8TwL6IuCUN8yUR8f5m1jkTdY7pY8DhiPjrZtZ2KiS9EHhhRDwkaTHwIPAm4B3Mw/dpmuN5C/P3PRKwMCIOSyoC3wPeC7wP+FpEbJL0GeDHEfH39faT95bEpcCOiNgZEUPAJmB9k2vKvYj4fyTPF6m2Hvh8+vrzJH/A80adY5q3IuKZiHgofX0IeJTkOfTz8n2a5njmrUgcTieL6VcAbwDuSuef9D3Ke0gsB3ZVTe9mnv/DSAXwTUkPSrqp2cXMkmUR8Uz6+pfAsmYWM4tulvST9HTUvDg1U0vSKuBi4Ae0wPtUczwwj98jSQVJDwN7gXuAx4EDETGSrnLSz7y8h0Srel1E/BvgauA96amOlpE+4rYVzpP+PfBiYC3wDPBfm1vOzElaBHwV+IuIOFi9bD6+T1Mcz7x+jyJiNCLWAitIzpy8bKb7yHtI7AFWVk2vSOfNaxGxJ/2+F/g6yT+O+e7Z9Lzx2PnjvU2u57RFxLPpH3EF+B/Ms/cpPc/9VeCLEfG1dPa8fZ+mOp75/h6NiYgDwHeA1wBlSWOPrj7pZ17eQ2IrsCbt7e8gecb25ibXdFokLUw73pC0ELgS+Nfpt5oXNgM3pK9vAP5PE2uZFWMfpqnfZx69T2mn6OeARyPib6oWzcv3qd7xzPP3qEdSOX1dIrlA51GSsLg2Xe2k71Gur24CSC9p+29AAbg9Iv5Lk0s6LZIuIGk9ALQDX5pvxyTpH4DLSYY0fhb4KPC/gTuB80iGhH9LRMybjuA6x3Q5yWmMAJ4E3lV1Pn9Ok/Q64LvAT4FKOvs/kZzHn3fv0zTHcz3z9z16FUnHdIGkQXBnRGxIPyM2AUuBHwFvi4jjdfeT95AwM7P68n66yczMpuGQMDOzuhwSZmZWl0PCzMzqckiYmVldDgmzDEi6XNI/NrDeOyS9qGr6s5J6s63OrHHtJ1/FzDL0DpIbtH4BEBF/0tRqzGq4JWG5Jelt6Xj7D0u6LR06HkmHJf1tOgb/vZJ60vlrJT2QDvb29bHB3iS9RNK30nH7H5L04vRHLJJ0l6SfSfpieldv9c+/FugDvpjWUJJ0n6S+qjo+mdbxLUmXpst3SromXaeQrrM1retdZ+jXZznhkLBcknQR8FbgtekAaKPAH6aLFwL9EfFy4H6Su6MB7gDeHxGvIrkzd2z+F4FbI+LXgN8gGQgOkpFE/wLoBS4AXltdQ0TcBfQDfxgRayPiaE2ZC4Fvp3UcAv6SZGiF3wc2pOvcCAxGxCXAJcA7Ja0+td+K2Yl8usny6reBXwe2pv/BLzExGF0F+HL6+n8BX5PUDZQj4v50/ueBr6TjZC2PiK8DRMQxgHSfP4yI3en0w8Aqkge/NGoI+Of09U+B4xExLOmn6b4gGZvrVWmrBKAbWAM8MYOfY1aXQ8LySsDnI+KDDax7qmPXVI+HM8rM/96GY2LcnMrY/iKiUjWKp4A/i4gtp1ij2bR8usny6l7gWknnwvizmc9Pl7UxMUrmHwDfi4hBYL+k16fz3w7cnz7FbLekN6X7WSCpawZ1HAIWn8ZxbAH+NB3mGkkXpqP/ms0KtyQslyJim6QPkzzBrw0YBt5DMnLp88Cl6fK9JH0XkAyr/Jk0BHYCf5TOfztwm6QN6X7ePINS/me6z6MkY/3P1GdJTj09lHaMDzBPHhlq84NHgTWrIelwRCxqdh1mc4FPN5mZWV1uSZiZWV1uSZiZWV0OCTMzq8shYWZmdTkkzMysLoeEmZnV9f8BKr1GN19rSSIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUujZ9bZDLEK"
      },
      "source": [
        "#Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "H0aTS3b1pMje",
        "outputId": "70adafa6-a69f-4895-c182-6831db6eebe3"
      },
      "source": [
        "net.eval()            #評価モード\n",
        "#今まで学習していない画像を1つ生成\n",
        "num_images = 1\n",
        "img_test = np.zeros([num_images, 3, length, length])\n",
        "imgs_test_ano = np.zeros([num_images, 4, length, length])\n",
        "for i in range(num_images):\n",
        "    centers = []\n",
        "    img = np.zeros([length, length])\n",
        "    img_ano = np.zeros([length, length])\n",
        "    for j in range(6):\n",
        "        img, img_ano, centers = rectangle(img, img_ano, centers, 7)\n",
        "    img_test[i, 0, :, :] = img\n",
        "\n",
        "img_test = img_test.reshape([1, 3, 64, 64])\n",
        "img_test = torch.tensor(img_test, dtype = torch.float32).to(device)\n",
        "img_test = net(img_test).to(device)             #生成した画像を学習済のネットワークへ\n",
        "img_test = img_test.cpu().detach().numpy() #torch.tensor - ndarray\n",
        "img_test = img_test[0, 0, :, :]\n",
        "\n",
        "plt.imshow(img, cmap = \"gray\")       #inputデータの可視化\n",
        "plt.savefig(\"input_auto\")\n",
        "plt.show()\n",
        "plt.imshow(img_test, cmap = \"gray\")  #outputデータの可視化\n",
        "plt.savefig(\"output_auto\")\n",
        "plt.show()\n",
        "plt.imshow(img_ano, cmap = \"gray\")   #正解データ\n",
        "plt.savefig(\"correct_auto\")\n",
        "plt.plot()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2da6wlVZXH/4uGph+0/aZtaSMQiYpGW9NBjY8gDoZxjCTGEB+ZMBOS/uJMNONEYCaZ6GQm0S8+PkxMOiMjHxzxPRBiVKYHMiGZIM2IykPkMci7L91N0003At2958Opc/jX4u51d9WtU+dC/X/Jza06e9eufapqn1prr7XXspQShBCvfE6adQeEEP2gwS7EQNBgF2IgaLALMRA02IUYCBrsQgyERQ12M7vIzO4xs/vM7IquOiWE6B5ra2c3s2UAfg/gQgCPALgVwCdTSnd11z0hRFecvIhjzwNwX0rpAQAws2sAXAwgO9hXrFiR1qxZAwBYtWpVreykk14UMp5//vla2fHjxyfbJ06cmGz7Hyou80zTecjMsvtdlUXnW4osdWetJtcwqpt7Nv2zyPVK21+2bFltn8fIKaecUivbt28fAOCFF17A8ePH521wMYP9DAAP0/4jAN4ZHbBmzRp87GMfAwBs3769VrZy5crJ9mOPPVYrO3DgwGT7ueeem2w/++yztXpHjx7NnpsfPr4RfAE90Y8HH3fyyfXLyPv+ppx66qnZMr65vO37yGX+QeG60UNaOhi5nj8maqOLwR5d/1Jy97fJDy3fT/+9Dh8+PNk+cuTIZNs/m08//XS2T7zP7a9bt65Wj8fItm3bamVXXXUVAODBBx9EjqlP0JnZTjPbY2Z7/vjHP077dEKIDIt5sz8K4LW0v636rEZKaReAXQBw9tlnp/e9730AgDe/+c21evxDsH79+loZ/2Lyr71/k/OvqReB+BeTy/zbletFohf/GvtzRe3zm3358uXZ4/htEolz/i3Bb6VIaiml7du7zZt9GqJ/G9UokqS8tMHPID+nzzzzTK0ev9k9fD5uf+3atbV6YxUYAN761rfWyu6//34AwP79+/PnyZYszK0AzjGzs8xsOYBPALhuEe0JIaZI6zd7SumYmf0VgJ8DWAbgqpTSnZ31TAjRKYsR45FS+imAn3bUFyHEFFnUYG/K8ePHcejQIQDA3Nxcreyhhx6abHu9w+u9Y3hmHgCOHTs22fb6X04n8/oZt/HCCy+8pP/zHed1ata3WUcH6jOqvA3Udfhotj/qf+lsfBumPfs+DXI6e5PZ+GjuI6ez8zaAyXMPvFTv5/b5meNjAGDTpk2TbT8HMNbn/bNYO0+2RAjxikKDXYiB0KsY//zzz+Phh0d+OCtWrKiV7d27d7LNjgq+LotY3nGBRaBIVGJ8PTYBetMee/ZFjjksuq9evbpWxuYUNqUAdbGeVZdS5xug3NTUhqGK8XyN/ffkZ5C3vU8Jq5y+DVYd/TPN8DPn2x/vh45g2RIhxCsKDXYhBoIGuxADoVed/dixYxOz2umnn56tF7mRsr7TdmVYpPuwuYMX4AB1cwfPD3jTGK/o27x5c62M63rTW25VUxOdvQsX2dIFKG0W00ybSBePKF1c5L9L7l74+5IzH/u6/Fx50y/fF182fo6ja603uxADQYNdiIHQqxh/4sSJibjhvd8i8Zz3o/XV7OHmVYGcl1K0imkcEGDMk08+Odlm8d+fi9chew86Fuu9aMcmRjbZ+TZYFfAqROm1KjWj5eIAtG1/2iJ9qWrX1vTmyQVT8W3kVl0C9eeWn02vkuU8LBfq4+SYBWsIIV4RaLALMRB6FeNTShMvND8LnhNlgHxsr0gVmO/cY9hjyXvJ8Yw7e/X5fe6jF8e57FWvelWtjL3wopndSFTn/WjmuOtZ9Ug0LaWLUFlN2mxzribfk+uWWkkiiwnfWx88JVp8NS6LroXe7EIMBA12IQaCBrsQA6FXnR14UY/0+gjv+7KcHuJ1ZT4uMkmVBnjwbZx22mmTbdb7fT/YbBZ5A/oyNrHltn0bpaGwI7NZqUnN666RZ9lSWQWXu79t4/l7+BmJngm+19GcgL/XTPRMjNuXzi6E0GAXYij0Ksab2UTc8CJsFKOdPctYPGKxCaiLQ16MYvGGRSB/XjYJelGU44rxuaOFMH7BD8cR8xk/WPxnlSHyBixd8ONF9dI0WlG9SMTvIptLjraLfbpIyxWZS/mZ8ynMooU2OZXKB3hhM65fRDV+lhSDTgihwS7EUNBgF2Ig9K6zj3UKr+eyvuN1MtZPWN+OdHav5+bcGr3ezG14vci78c7Xtj/3hg0bamWss7NeDtR1fT53E509l6suSiFcapbrYtXbNCh1l+1CZ4/aLHWJje4Zu4B7/TsyvY2fnei8C77ZzewqM5szszvosw1mdoOZ3Vv9Xx+1IYSYPSVi/LcBXOQ+uwLA7pTSOQB2V/tCiCXMgmJ8Sum/zexM9/HFAM6vtq8GcBOAy0tOOBZNvIgcmWq4LpsjvNmM24g8kSIvNo7l3iTABsNlXlTfuHFjtoz3WaSPvAE9uXj2/vpGaYhzontpvaVEF3HjS1fqRW1EeQZKn1tWdf0zMT5uGh50W1JKj1fbTwDY0rIdIURPLHo2Po1+2rKzMWa208z2mNkev4ZdCNEfbWfj95rZ1pTS42a2FcBcrmJKaReAXQCwefPmlPOgi8RArstifDQDXBogwKsTuVl7oC5GcT2vTkTxxlg894EtuIy/Z/Rdojh8UR9zs8hA3msumtFfqgthmHCmOrBwdCHG8zPsnwm+rlzP37MooMn4uEXNxme4DsCl1falAK5t2Y4QoidKTG/fBfA/AN5gZo+Y2WUAvgzgQjO7F8CfVPtCiCVMyWz8JzNFH+y4L0KIKdK7B91Yl4n0xFKdKTQzuPZzuoz/vE2gx8gE6NvP6eVAXq/zbUR6dC6gRFuvsOjzNsEtI7pOMe2J9PK2Ojt7cUbBPErbb5tyu6SufOOFGAga7EIMhN7jxo/Fm9IY7wvVbVOPRaqcCQN4aQAMX3dMtEDEi+CRF1RuIUUX8dqbEAVrWGx7bSkNWFGq2rUV4/314HvIC6WafOfSmH8lZlBlcRVCaLALMRQ02IUYCL3HjR/ThXtlk2Ny+o43m0XpnHNBMaNgmZFu6INvcDulpjdPFCByqVMa8KGN2dC330Rnj0xqOffkyPTbxLTXJXqzCzEQNNiFGAgzE+OnQWSaYEpjpntY3OJ6TWLhccw7L+rlYot7E11knllsvYXqdk0b0b2LGHGRqN4kflwujbK/hm0DZ3SJ3uxCDAQNdiEGwszE+C5mJNsGGeDUPD56Dsed8yl8uIyP82I8e8lxTDugLv57Dz2OP5bz1luIrr0N29L1/ewiflwkqpem1PKUej1GZblFYKXfhfeVxVUIocEuxFDQYBdiILyiTG8RrKOyjv3ss8/W6j3zzDOT7QMHDtTK9u/fP289r7NzUIrXve512TIfcJLnCNhk5/Wz0rmJUtPbNCiNsR8F+sjR1jzVVh+OYHNbzgNyoTa7ML0peIUQYoIGuxADYckshGlDJBp5MSonVnqPORalDx06VCvbt2/fZPvIkSPZNjiNk1cTWOSPYteVxpmL6OIaR6pAtKCoNCZdaR8jMbtUPI8Ch0SmzlIRvO1il649BXPozS7EQNBgF2IgaLALMRB619lzOlqbYJGR7uZ1doZ1tyioJMd4B+q6eKSfsYusb4NdYv25c6vemgScbOMuG6164+1IL/fmR96PdPtobiL3XZq4y/I15evtVyPyffFpk/m40vmCJubSJRO8wsxea2Y3mtldZnanmX22+nyDmd1gZvdW/9dPv7tCiLaUiPHHAHw+pXQugHcB+IyZnQvgCgC7U0rnANhd7Qshliglud4eB/B4tX3YzO4GcAaAiwGcX1W7GsBNAC4vPXGTdEGl6YhYZPOmlFy65Uj89LD3G6+A87DovmHDhloZi/heXOQ+R3HPojjmXXvQRcexSM6x+4C6CbO0nl9lyHVzsd6A+n336htfY75/PvVWlGY7l/bL70fBK0rTRbdJE7VQ+5M6C9aon+xMAG8HcAuALdUPAQA8AWBLk7aEEP1SPNjN7DQAPwLwuZRSzdskjX7G5n0FmNlOM9tjZnv82nEhRH8UDXYzOwWjgf6dlNKPq4/3mtnWqnwrgLn5jk0p7Uop7Ugp7fCikxCiPxbU2W2kHHwLwN0ppa9S0XUALgXw5er/tSUnXKzpLTJv5MwsvqxUB/M6NevbkQ7JZh021wH1lW4rV67M9rF0ZVufRO6yfq4jFw3Iuw+zS7J3T2aXZNbfm9x3vmcc7NOvOOQ2/H2PVvDl5lk83K9onmWxse2j56bEzv4eAH8O4Ldmdnv12d9hNMi/b2aXAfgDgEsK2hJCzIiS2fibAeR+Lj7YbXeEENNiZh50kemtbRzzyIOOResoLTOXRSvWItGOxS0vqrNY78si9YJpEyu+baqsqA1WZbzZjEV3DvTBKwcB4LHHHsuW5QKERMEivQjO4voZZ5wx2X71q19dq8f33c8t8X0qFa39883PmS/j/ciMWOopmEO+8UIMBA12IQZCr2J8Smki+rUV46M4X6WiNYvLUez21atX18r43JFYzOfy7bN3nRc5c7PxbVM3deFBx/fJ3zMWrb1nXC6WH4vtAPDQQw9Ntr0Yf/jw4XnPVbrYBQDWrl07bx+j++Jj/fN9L03ZFVkuouzA0UKvKLOv4sYLISZosAsxEDTYhRgIMzO9eY8r1kF8gAPej7y2GF/Genqk+0T6fI4oUEG0+i4KcthFuuW2ed9KvRwj0xvr2wcPHpxs+1j8XPb000/Xytj0Gc3VRNeby9gM57312FTov0s0F1Sqs0febzlzW5PAmuPjpLMLITTYhRgKvYvxYzHcm2pY/CoNcFDqiRThY5FFZrOciBV5dJWaaoC8eaZtDLqoXpu4Z5E5yYu+R48enWyzGS5KkR0F6Yg8y6LrzbAqUBozz1NqDvPfhZ9v335uMU2TtNKdB68QQrx80WAXYiBosAsxEGbmLut1N9aPfTDHNql8/Yoydk3lMl+PVzx5d9bcyjmvQ5aaT6L+R5TGfC9toy1RTPmcDuz11ShIaK6Pvl70fJQGlyg1r0Wm1Lb5+XJ6epO5IOnsQogJGuxCDITexfixeOcDQzAcewyoi4Rs0onMJ5FozSuceFUUAKxf/2JiG7/6iQNPRGJf5OkUkVtVNw0PutJVdblj/H5UxiJmdF8iMT6XetkTea7xuaJUVlE6Z3/uXFAK/2xGJtdcH5t40GnVmxBigga7EAOhdzF+7GnlZ+NZVPJlOa859swC6osvovRMHFKY45IBdfVi06ZN2TZKRbuIrheq+LKuQ06XiupA/frkrBh+39/3XMw/P9PN/YjEc96OvAEjSmfBo3ql6lVbtSmH3uxCDAQNdiEGgga7EANhZsErovS8XndjHYd1cR8IYe/evZNtr88zbG7zOh7rmlH8cDbDRfpem9VlTZhGKqicLh7pod5cxd6HubTJft+bY/le8zX296z0GkcmwEinXioei4ttb8E3u5mtMLNfmtmvzexOM/tS9flZZnaLmd1nZt8zs+ULtSWEmB0lYvxzAC5IKb0NwHYAF5nZuwB8BcDXUkqvB/AUgMum100hxGIpyfWWAIxl4lOqvwTgAgCfqj6/GsAXAXxzgbYm4pgX46MY5LngFd7TjsX/0hh3kTrh28jFwos8orzoWxpvPsoS24YoMERE9F3YxOhNahxzn6+pN4lyme8Ti/98n6IYdB72gtywYcNk22dx5f56VSNaTBOlfOqaxaoCpfnZl1UZXOcA3ADgfgAHU0rj0fAIgDNyxwshZk/RYE8pHU8pbQewDcB5AN5YegIz22lme8xsj3+LCiH6o5HpLaV0EMCNAN4NYJ2ZjeWbbQAezRyzK6W0I6W0w4t6Qoj+WFBnN7PNAF5IKR00s5UALsRocu5GAB8HcA2ASwFcW3LCsV4TuTX6MtbruJ53S2U9zOtkrGux6e3000+v1WN9rTSwYZPAgH1S6lZb6noZpcH2QUDYJZnvkw8Iwtfbr0DkFY7RHEbktssrHLlPW7ZsqdXj58CvduQ+N5kvyDENc2lJmyV29q0ArjazZRhJAt9PKV1vZncBuMbM/gnArwB8azGdFUJMl5LZ+N8AePs8nz+Akf4uhHgZ0LsH3Rhvpoi8lHIiM3uxAeXx41hM27hxY60et+nbYHG0bZABpuu47hFtTW+52O1A/XqwuOzhel714vvixXj2qIsmd6P0T6xesBjv1Tde4eifq1Ixfhom0i6Rb7wQA0GDXYiBMDMxvokIm0v940VCPi4SxbjMz7yy2DeN9E+R513XYmBbkTDXD/85Xx/vdZaL+efFfb7efvESz8ZHnnbR9WbPOBbV2ZsOqMce9M9OFDb85YTe7EIMBA12IQaCBrsQA6F3nX2sbzXRcxk2rUTmpGi1GXtjeW+9NvHguw4MOA2iII2lKakiXTlKycTX1Ou8UQqpaH4jdy7vks1zMrltoD6X4E2u/N2i9NlLIUBFhN7sQgwEDXYhBkLvYvxY5IrEvlIvJR/kgoNNeI8rPo6DXkSikjcneTFzvrbn258mUf/bBlPIqTJtPf7aehTm4hL678UmwEgFLM3G2mSxS06Mb+IhOk2vOUZvdiEGgga7EANBg12IgdCrzm5mWZ2d9yOXRNaFfHx5drf0+jzr22xmiUxS3m2S5wSivGFd0zbXW2mbkQkzMkW2wV9vvqY+GCWvejt06NC8xwB1c5v/Lmxii0yAkRkxWuGYS7PtKdXZ29Rb6Nxj9GYXYiBosAsxEJaM6S0yizAsrnhxjsV4XjEF1MUtFv+j2Gm+/Vz6Xy+aRp5f0XHT9MZqQqnprbSPpfEFvbmUxXou8yoa9zGK9R+pJGx6i8zCnpy5ra3pLVIPS9oI8xJkS4QQryg02IUYCL3Pxo/Fde+dFgVCyImBfjaeRfJo1pRn2VlsB8oXRJSGi24iiuVEuCZttKGL2fhS0TQSb6OgJfxM+MUuvO/LcotY2no9RipbqWrXtg3NxgshitBgF2IgaLALMRBmprP7wINRKqGc6cObSLjNSIfhIIReZ+eghD6FFLfP/S01zSzUrzb12sL6YBRQIiJa5VU6/8C6sg/wWXq9o/ke3u8iCIX/nrlAKF3o7E3manIrMpniN3uVtvlXZnZ9tX+Wmd1iZveZ2ffMTFkbhVjCNBHjPwvgbtr/CoCvpZReD+ApAJd12TEhRLcUifFmtg3AnwH4ZwB/YyMZ6AIAn6qqXA3giwC+uUA7E3HMi/EsbnkRJefd5Nvg2N/RQgc2qXlRnVMQ+YUwvKiCxcq2KZ5KRfy+F9rkvk/bhRmReY3vpxfBc56UkYdbpNqVBrmITKLTEMHbmO+m6UH3dQBfADA+20YAB1NKY9/ERwCcUdiWEGIGLDjYzewjAOZSSre1OYGZ7TSzPWa2xzvBCCH6o0SMfw+Aj5rZhwGsAPAqAN8AsM7MTq7e7tsAPDrfwSmlXQB2AcCmTZtmt7pDiIFTkp/9SgBXAoCZnQ/gb1NKnzazHwD4OIBrAFwK4NqF2op09igefM6F1a9+Yp3G62Q518vIvObdZXk/CrZRqqdHASHbBqiYhvtsSb0mei6Tuy/+uEgvj/IFRIEkc0T9nba7bNuglSXBRRfjVHM5RpN192Gkw39rEW0JIaZMI6ealNJNAG6qth8AcF73XRJCTIPePejGIlgUt9uLKOxRx9uR6BKtfmJxkb3p/HFe7CuNk9e1CD5tsd1fx8gslTt36aq3KN2WJ7dKLTomSiEVebhxWaSWRcd1veqtdFUklyl4hRBCg12IoTAzMd6L2dFsK+/743Jt+MU0uQAHvl60WCJ3Lk/bIANtglJMO9VU6aKQtsErohh0Pp7cmChDrxfB+XxsTfHn4n5EGYbbivFR5uBcG5HKM9WFMEKIlzca7EIMBA12IQZC73Hjc6Y3JjJ5RTp1tIKKTXuss/uACZEnH1OqXzfxdMqZmpoER+wzXTRTusrL65YcG57TPQH1gKKsY0fX0Hs98vl4fiaaH4hWTHZhNmubL0ABJ4UQRWiwCzEQZhaDLvJSikwfLKaWivtAXVyPUv1EYnDp4o62sdZzNBHbc4tCShZKLIa2cddZzPZZXDmdF297ETzKvMsqG6sFfhEVi/H+megr8MR8Zbl6uTJ50AkhNNiFGAoa7EIMhJmlbI5cHr3+x3WjHGttzFU5l0wg1ruiFVTReXmeoW2+sShYQ2k/uia6Z1F/ucxfR743rG8fOXIkey5vSuU22sZ1Z7rIz1dqeus60Kje7EIMBA12IQZC76a3sdjWhRdYJFJFK4uYKLWzF/FzK7QiscybcdqkF/aUrsaLRORcf5vA5/Jt5FYx+uvBak2Uitl7RObaiDwncym3PU2CRuTE7uiZmAbyoBNCTNBgF2Ig9D4bPxYtI/E5yrAZhYsuXdwf1WNR3S/M4P2jR49Otr1HF+PFSg5d7ePflWYcjawOpWmXulh8EfUjZ3XwojovTolUL74e3vuNz+WDkbBHHS+SaZt5t9SDrq0q0BaJ8UKICRrsQgwEDXYhBsKS0dnbrMoq9XDj8/oyX4/18sOHD9fKDh48ONk+dOjQZNuv1mIdktM8+z76a5CLSx95nXlKvbEWGwjBE+nAUVkUKJGvAc+LRGY+70HHOjvPiTTR2aOyXN3I9NZ2BeJidfvS/OwPAjgM4DiAYymlHWa2AcD3AJwJ4EEAl6SUnlpUb4QQU6OJGP+BlNL2lNKOav8KALtTSucA2F3tCyGWKIsR4y8GcH61fTVGOeAuLz14GgszSsV4Foe82YyDJBw4cKBW9tRTLwouc3Nz8x4D1MXx17zmNbWyyCuMzUZcrwvTWxPRsY3nXenipSYx39lUljOdLtQ+X2MW8SMxvom3Ye4aN4k9OG3vujGlb/YE4BdmdpuZ7aw+25JSerzafgLAls57J4TojNI3+3tTSo+a2ekAbjCz33FhSimZ2bw/T9WPw07gpbnQhRD9UfRmTyk9Wv2fA/ATjFI17zWzrQBQ/Z/LHLsrpbQjpbRj1apV3fRaCNGYBd/sZrYawEkppcPV9ocA/COA6wBcCuDL1f9rS06Y05VKg1IwTWJz58xt3iWWAyP4IAlsbmN93rfBuqY3361bt26y7VfVlerVkc6eo4mpszRgZpRGORewIjIjerNZmwAhkdsu35coqGTb4BWRzt6GrvMFlIjxWwD8pGrsZAD/nlL6mZndCuD7ZnYZgD8AuKSgLSHEjFhwsKeUHgDwtnk+3w/gg9PolBCie3r3oBuLOk1WBeXKvLiV85Lzx7H47L3fONaZF7N5P/LaapNCCiiPZ9aGtm209cJj+HuVxqoD8inCmsTij1KB5/oYUaoe+uevVDVoE6tuvv35kG+8EANBg12IgaDBLsRA6FVnP3HixEQn9m6quWCOQBxrPUeku/G5WEdvUhYFSox09kgn4/Z5LiFyiS3NTdd2jqQ0f1mkk7Yxq/rjIvfW0mei1OW2yZwA3zPe9vM90f3kuvzs+4g8UfvjMuV6E0JosAsxFHoV41NKE9HYi8gslnjxpXS1EhOZeHKil+9HtHKO++RXa5UGa4iCYrJYHKWoKl291UQE71qML03/1DbQaBvVLjLbNhHjWTyPcg5wPf+85I6LAnD6svFxEuOFEBrsQgyF3sX48Wwjx10fl43xIhDPdrMI5EUWLos86ErEofnazxGJW9Fil6isdLa8VPRtm1W0rRifsxg0EZ9z4n8X2W9LrQAL1eV7zSph5GlXmrYsympbmt6M0ZtdiIGgwS7EQNBgF2Ig9O5BN9bVfVCHSN9mHSrSTaL8aLlcYd5bj02Cfl6BA0ty/33wCsa3v379+sm2D9OV08ki05snp2+XzmH446I2orIcTTzhcjp2k2ClpW2UlkUedJFOzc+BN73l5nH8fZfpTQhRhAa7EAOhd9PbWGTxZoVosQuX+UARDIvqUUAJxi9iYaIFCyzic2w6oC5Kcdwz30Z0Dbi/vu9RaqicGOe/S2S+KxXPI9E3aj/qV2n7pW30CffDi+rR/WT4eYlSU/v7Pn6OQ5NitkQI8YpCg12IgaDBLsRAWDIpm5lSU5CnSXDHHJEJkPVtNr15MyKfi+PEA3U9rNSFNVp952mTe6zUDbZtG21pu8KxTb1S05snZw5rEiykDW1chvVmF2IgaLALMRB6FePNLCtu8OJ+LxazCOQ90hg2aXjvIy5jccuneGJvOG/64D5yPe9Bx9+xiYcem/BY1PNmxMgEw3QhgpfGQo889GZJ7nlrYsqL6ua85vz35+fA309un59H/1zxfc/FcFy0B52ZrTOzH5rZ78zsbjN7t5ltMLMbzOze6v/6hVsSQsyKUjH+GwB+llJ6I0apoO4GcAWA3SmlcwDsrvaFEEuUkiyuawG8H8BfAEBK6XkAz5vZxQDOr6pdDeAmAJcv0NbEQ8h7GEViMYsmXrRm2BsuimPH4qcXpVmF8HHy+LiVK1dm+xF5/HGb3vOOVY1I7Gsjxk8jM2mpGL/URfqF6kUz9fyclQZF8c8+txmlH8s9H6WUvNnPAvAkgH8zs1+Z2b9WqZu3pJQer+o8gVG2VyHEEqVksJ8M4B0AvplSejuAI3Aiexr9dM/7821mO81sj5nt8W9KIUR/lAz2RwA8klK6pdr/IUaDf6+ZbQWA6v/cfAenlHallHaklHasWLGiiz4LIVpQkp/9CTN72MzekFK6B6Oc7HdVf5cC+HL1/9qF2lq2bNkkeAMHcQBi8xrrKl7fYVh/9fVyeq5fgcQ/SFFQP9azfNpnbn/t2rW1sjVr1sx7LqA+58B6uu9jlBYpF2ihSfpf/p583SITXenqu5eD/t7E9Fb6PUvnC6LVcatXr55s++d7HAglGh+ldva/BvAdM1sO4AEAf4mRVPB9M7sMwB8AXFLYlhBiBhQN9pTS7QB2zFP0wW67I4SYFr160C1fvhzbtm0DALzpTW/K1uNYb55ITGEx2AeNyAWp8CI4ezB5sxzvRxk1WaRdtWpVrYzVF79I5rTTTptss2kvUkmiNFddZHGNVIHItFcak24p0iRufJI/5+AAAAQxSURBVC5mnP/+/LxE7XMb/rysAr7lLW+pld11110A4sAY8o0XYiBosAsxEDTYhRgIvershw8fxk033QQA2LdvX61s06ZNk22vK7MpLtKf2FzlY7KzmYt1Jq9v87m8Pp9L9Rzpq968tnHjxsm219m5bmR6axNDvYmra04Xj+KYR27Mbc1tUbz2xbbXhMgluU3c+CiAaM7sCdTncfbv318ru/nmmwG8dMUooze7EANBg12IgWB9ejSZ2ZMYOeBsArBvgerTZin0AVA/POpHnab9eF1KafN8Bb0O9slJzfaklOZz0hlUH9QP9aPPfkiMF2IgaLALMRBmNdh3zei8zFLoA6B+eNSPOp31YyY6uxCifyTGCzEQeh3sZnaRmd1jZveZWW/RaM3sKjObM7M76LPeQ2Gb2WvN7EYzu8vM7jSzz86iL2a2wsx+aWa/rvrxperzs8zslur+fK+KXzB1zGxZFd/w+ln1w8weNLPfmtntZran+mwWz8jUwrb3NtjNbBmAfwHwpwDOBfBJMzu3p9N/G8BF7rNZhMI+BuDzKaVzAbwLwGeqa9B3X54DcEFK6W0AtgO4yMzeBeArAL6WUno9gKcAXDblfoz5LEbhycfMqh8fSCltJ1PXLJ6R6YVtTyn18gfg3QB+TvtXAriyx/OfCeAO2r8HwNZqeyuAe/rqC/XhWgAXzrIvAFYB+F8A78TIeePk+e7XFM+/rXqALwBwPQCbUT8eBLDJfdbrfQGwFsD/oZpL67offYrxZwB4mPYfqT6bFTMNhW1mZwJ4O4BbZtGXSnS+HaNAoTcAuB/AwZTSeDVHX/fn6wC+AGC84mbjjPqRAPzCzG4zs53VZ33fl6mGbdcEHeJQ2NPAzE4D8CMAn0sp1TJF9NWXlNLxlNJ2jN6s5wF447TP6TGzjwCYSynd1ve55+G9KaV3YKRmfsbM3s+FPd2XRYVtX4g+B/ujAF5L+9uqz2ZFUSjsrjGzUzAa6N9JKf14ln0BgJTSQQA3YiQurzOz8frLPu7PewB81MweBHANRqL8N2bQD6SUHq3+zwH4CUY/gH3fl0WFbV+IPgf7rQDOqWZalwP4BIDrejy/5zqMQmADhaGwF4uNFlR/C8DdKaWvzqovZrbZzNZV2ysxmje4G6NB//G++pFSujKltC2ldCZGz8N/pZQ+3Xc/zGy1ma0ZbwP4EIA70PN9SSk9AeBhM3tD9dE4bHs3/Zj2xIebaPgwgN9jpB/+fY/n/S6AxwG8gNGv52UY6Ya7AdwL4D8BbOihH+/FSAT7DYDbq78P990XAG8F8KuqH3cA+Ifq87MB/BLAfQB+AODUHu/R+QCun0U/qvP9uvq7c/xszugZ2Q5gT3Vv/gPA+q76IQ86IQaCJuiEGAga7EIMBA12IQaCBrsQA0GDXYiBoMEuxEDQYBdiIGiwCzEQ/h+IYl06Owe9SgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}